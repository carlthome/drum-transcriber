%***** NOTE: This version requires MatLab R2008a or later%**************************************************%Version 2011-08-23%%PattRecClasses - Some Object-oriented Tools for Pattern Recognition Purposes,%including Hidden Markov Models (HMM)%and some probability distributions, e.g., Gaussian Mixture Models (GMM)%and Vector Quantization (VQ).%%An HMM is a MatLab object representing the statistical properties of data sequences.%The sequence elements may be scalar (integer or real) or real-valued column vectors.%%HMM objects can be automatically generated and adapted to given training data.%An array of HMM objects can then be used to classify new data sequences.%%Requirements:  Main class HMM needs several other classes:%               MarkovChain, GaussD, GaussMixD, DiscreteD.%               The GaussD class needs VQ class for initialization.%%**************************************************************************%*****  Example of HMM Usage: *****%% 1:    Create a set of HMM:s using sets of observed training data%% for m=1:NumberOfModels    %collect training data typical for each type of source%     trainingData=zeros(DataSize,0);   %empty store for training sequences%     trainingLength=[];    %to store the length of each training sequence%     for r=1:NumberOfTrainingSequences%         x=recordVectorSequence;   %training sequence of vectors, stored columnwise%         trainingData=[trainingData,x];    %accumulate sequences%         trainingLength=[trainingLength,size(x,2)];    %save length of each sequence%     end;      %now we have a set of training sequences from source# m%     hmm(m)=MakeLeftRightHMM(10,GaussMixD(5),trainingData,trainingLength);%construct model% end;% hmm(:) is now an array of trained left-right HMM:s,% each having 10 states and 10 GaussMixD probability distributions,% with 5 mixed Gaussian sub-distributions for each state.%% 2:    Classify a new data sequence using the array of HMM:s%% y=recordVectorSequence; %test sequence obtained from unknown source type% lP=logprob(hmm,y); %calculate conditional log(probabilities) for y, given all hmm:s% [maxlP,bestHMM]=max(lP);% %bestHMM is now the index of the HMM that most probably generated y.%%For other examples, see the included testExamples/testXxxxxx programs%**************************************************************************%Class structure:%%ProbGenModel   abstract superclass for Probabilistic Generative Models%               (as opposed to Discriminative Models)%ProbDistr      abstract superclass for probability distributions%               that can be used as HMM output distributions or MixtureD components.%@HMM/HMM       definition of HMM class%@etc...%%A general HMM is an object consisting of two sub-objects%1: one State Generator of class MarkovChain, with NS states, and%2: one Output Distribution array containing NS probability distribution objects.%%The output distribution objects can be of class GaussD, GaussMixD, etc.%%For introductory information, use "help HMM", etc.%%For implementation details, study the class definition files, e.g. @HMM/HMM.m%*************************************************************************%%Probability distributions:%   @GaussD/GaussD.m%   @GaussMixD/GaussMixD.m%   @DiscreteD/DiscreteD.m%Vector Quantizer:%   @VQ/VQ.m%%These  classes can also be used separately, outside the HMM context.%The GaussMixD class is a general Gaussian Mixture Model (GMM).%%**************************************************************************%High-level design methods:%%   MakeLeftRightHMM    - create and train a left-right HMM to given data%   MakeErgodicHMM      - create and train a stationary ergodic HMM to given data%   MakeVQ              - create and train a vector quantizer to given data%%Medium-level HMM training methods:%%   @MarkovChain/initLeftRight  - initialize a left-right MarkovChain, for later training%   @MarkovChain/initErgodic    - initialize a stationary ergodic MarkovChain%   @HMM/HMM/init       - initialize an HMM object to given data%   @HMM/train          - train an initialized HMM object to given data%%Low-level training methods:%%   adaptStart - initialize data structure for training%   adaptAccum - accumulate statistics,%              called iteratively for each training sequence%   adaptSet   - finally set the trained object%%These low-level methods are available for all classes,%HMM, GaussD, GaussMixD, MarkovChain, etc.%%**************************************************************************%%Various support functions%   cluster     - hierarchical clustering of data%%****************************************************%%References:%Leijon, A. (200x) Pattern Recognition. KTH, Stockholm.%Rabiner, L. R. (1989) A tutorial on hidden Markov models%	and selected applications in speech recognition.%	Proc IEEE 77, 257-286.%Cover, T. M. and Thomas, J. A. (1991) Elements of Information Theory.%   John Wiley & Sons, New York.%%Arne Leijon