function [hNew,hGen]=testErgodicHMMES%test of HMM-Extended-state adapt, logprob, rand%Arne Leijon 2011-08-04 testedc='rbgk';%state color coding, max 4 statesstateD=[10 20 30];%state durations%ergodic generator HMM:% nStates=2;% A=[.95 .05; .05 .95];% p0=[0.5;0.5];nStates=3;A=[.95 .03 .02; .03 .95 .02;.03 0.02 0.95];p0=[1;1;1];mc=MarkovChain(p0,A);%fairly difficult for ergodic HMM, because GaussD are highly overlappingpDgen(1)=GaussD('Mean',[0 0],'StDev',[3 1]);pDgen(2)=GaussD('Mean',[+1 0],'StDev',[1 3]);pDgen(3)=GaussD('Mean',[-1 0],'StDev',[1 3]);%hGen=HMM('MarkovChain',mc,'OutputDistr',pDgen);hGen=HMM(mc,pDgen);%Make many training data sequences:nPeriods=40;xTraining=zeros(2,0);%training datalxT=[];%lengths of sub-sequencessT=[];%generator statesfor nP=1:nPeriods    x=zeros(2,0);%space for single period    s=[];%corresponding state indices    for i=1:3%each state        x=[x,pDgen(i).rand(stateD(i))];%generate fixed number of observations        s=[s,repmat(i,1,stateD(i))];%state index for each observation    end;        if 0.5<rand(1)%50% chance, original state order            xTraining=[xTraining,x];            sT=[sT,s];        else%reverse state order            xTraining=[xTraining,fliplr(x)];            sT=[sT,fliplr(s)];        end;        lxT=[lxT,size(x,2)];%lengthsend;%hNew=InitErgodicHMM(nStates,[],GaussD,xTraining,lxT);%OLD version%replace the standard MarkovChain by a MarkovChainESmcNew=initErgodic(MarkovChainES,3,10);mcNew=mcNew.splitStates(3);hNew=init(HMM(mcNew,GaussD),xTraining,lxT);disp('Initial Mean State Duration');disp(mcNew.meanStateDuration);figure(1);plot(mcNew.probStateDuration(50)');title('Initial State Durations');xlabel('state duration');ylabel('p(state duration)');%Now train it on the datafor nTraining=1:30    figure;    plotTraining(xTraining,sT,c);    %also plot error points, as classified by viterbi...    plotCross(hNew.OutputDistr,[1 2],c); 	axis([-10 10 -10 10]);	hold off;%	pause;    %one training step:    ixT=cumsum([1,lxT]);%start index for each sub-sequence    aS=adaptStart(hNew);    for r=1:length(lxT)        aS=adaptAccum(hNew,aS,xTraining(:,ixT(r):(ixT(r+1)-1)));    end;    hNew=adaptSet(hNew,aS);end;hNew=setStationary(hNew);disp('Trained Mean State Duration');disp(hNew.StateGen.meanStateDuration);figure(99);plot(hNew.StateGen.probStateDuration(50)');title('Trained State Durations');xlabel('state duration');ylabel('p(state duration)');lP=zeros(1,length(lxT));%space for resultstartT=[1,1+cumsum(lxT)];%start indices in xTrainingfor n=1:length(lxT)    lP(n)=hNew.logprob(xTraining(:,startT(n):(startT(n+1)-1)));endfigure(98);plot(lP,'or');function plotTraining(xT,sT,c);nStates=max(sT);for s=1:nStates    plot(xT(1,sT==s),xT(2,sT==s),['o',c(s)],'MarkerSize',1.5);    hold on;end;