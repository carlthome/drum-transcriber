function [hNew,hGen]=testErgodicHMMtied1%test HMMtied design,%using GaussD output distributions%Arne Leijon 2009-07-28 testedc='rbgk';%state color coding, max 4 states%ergodic generator HMM:% nStates=2;% A=[.95 .05; .05 .95];% p0=[0.5;0.5];nStates=3;A=[.98 .01 .01; .01 .98 .01;.01 0.01 0.98];p0=[1;1;1];mc=MarkovChain(p0,A);%difficult for ergodic HMM, because OutputDistr are highly overlapping%needs a lot of training datapDgen(1)=GaussD('Mean',[0 0],'StDev',[3 1]);pDgen(2)=GaussD('Mean',[+1 +0.1],'StDev',[1 3]);pDgen(3)=GaussD('Mean',[-1 -0.1],'StDev',[1 3]);% pDgen(4)=GaussD('Mean',[0 +4],'StDev',[2 1]);% pDgen(5)=GaussD('Mean',[0 -4],'StDev',[2 1]);%state#1 is mix of pDgen(1 4 5); other states are single GaussD%mixW=[1 0 0 1 1;0 1 0 0 0; 0 0 1 0 0];mixW=eye(3);hGen=HMMtied('StateGen',mc,'GaussComp',pDgen,'MixWeight',mixW);%Generate training data sequences:xTraining=zeros(2,0);%training datalxT=[];%lengths of sub-sequencessT=[];%generator statesfor i=1:2    [x,s]=rand(hGen,2000);    xTraining=[xTraining,x];    sT=[sT,s];    lxT=[lxT,size(x,2)];end;%Train a new HMMtied using the data:gD=init(repmat(GaussD,3,1),xTraining);mcNEW=initErgodic(MarkovChain,nStates,10);%real duration =50mixW=mixW+0.1;hNew=HMMtied('StateGen',mcNEW,'MixWeight',mixW,'GaussComp',gD);for nTraining=1:5%train only OutputDistr first, using initial MarkovChain    figure;    plotTraining(xTraining,sT,c);    plotCross(hNew.GaussComp,[1 2],'k'); 	axis([-10 10 -10 10]);	hold off;    %one training step:    ixT=cumsum([1,lxT]);%start index for each sub-sequence    aS=adaptStart(hNew);    for r=1:length(lxT)        [aS,logP(nTraining)]=adaptAccum(hNew,aS,xTraining(:,ixT(r):(ixT(r+1)-1)),1);    end;    display(logP);%****only for test    hTemp=adaptSet(hNew,aS);    %hNew.GaussComp=hTemp.GaussComp;    hNew.setGaussComp(hTemp.GaussComp);    %mixNew=get(hNew,'MixWeight')%testend;for nTraining=1:20    figure;    plotTraining(xTraining,sT,c);    plotCross(hNew.GaussComp,[1 2],'k'); 	axis([-10 10 -10 10]);	hold off;    %one training step:    ixT=cumsum([1,lxT]);%start index for each sub-sequence    aS=adaptStart(hNew);    for r=1:length(lxT)        [aS,logP(nTraining)]=adaptAccum(hNew,aS,xTraining(:,ixT(r):(ixT(r+1)-1)),1);    end;    display(logP);%****only for test    hNew=adaptSet(hNew,aS);    mixNew=hNew.MixWeight%test    transProb=hNew.StateGen.TransitionProbend;hNew=setStationary(hNew);figure;plot(logP);function plotTraining(xT,sT,c)nStates=max(sT);for s=1:nStates    plot(xT(1,sT==s),xT(2,sT==s),['o',c(s)],'MarkerSize',1.5);    hold on;end;