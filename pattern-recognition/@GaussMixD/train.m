%function [gm,logprobs]=train(gm,xT,nIterations,minStep);%adapts a single GaussMixD object to an%observed set of (possibly vector-valued) samples.%%Input:%gm=    single GaussMixD object%xT=    matrix with a set observed vectors, stored columnwise%nIterations=   (optional) min number of iterations%minStep=       (optional) min logprob improvement/training obs.vector%               = desired improvement in relative entropy/ obs.vector,%               in each iteration step.%typically, minStep=log(1.01); for 1% average relative-entropy improvement.%%Result:%gm=    new trained GaussMixD object%logprobs=  vector with mean logprob/obs.vector, achieved during training%%Method: apply methods adaptStart, adaptAccum, and adaptSet.%       The GMM must be previously initialized to the format of the%       training data.%%Arne Leijon 2009-07-21 testedfunction [gm,logprobs]=train(gm,xT,nIterations,minStep)if numel(gm)>1    error('Method works only for single object');end;if nargin<3    nIterations=10;end;%defaultif nargin<4    minStep=realmax;%to prevent conditional training steps% else%     minStep=minStep*size(xT,2);%min desired increment in total logprobend;logPold=-realmax;%logP=mean(logprob(gm,xT),2);%before any traininglogprobs=zeros(1,nIterations);%space for minimal number of training stepsfor nTraining=1:nIterations%min number of iterations    logPold=logP;    aS=adaptStart(gm);    aS=adaptAccum(gm,aS,xT);    gm=adaptSet(gm,aS);    logP=mean(logprob(gm,xT),2);    logprobs(nTraining)=logP;%accumulate training result%    display(logPold);display(logP);%testingend;while logP-logPold>minStep%continue training if sufficiently good improvement    logPold=logP;    aS=adaptStart(gm);    aS=adaptAccum(gm,aS,xT);    gm=adaptSet(gm,aS);    logP=mean(logprob(gm,xT),2);    logprobs=[logprobs,logP];%    display(logPold);display(logP);%testingend;